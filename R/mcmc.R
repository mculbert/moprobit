
#' Multivariate ordinal probit MCMC iteration
#' 
#' Run forward n iterations of the Gibbs algorithm starting from `state`
#' 
#' @param state A moprobit state container, generated by [moprobit_init()].
#' @param iters The number of iterations to run.
#' @param TMN_iters The number of sub-iterations for sampling from the Truncated Multivariate Normal distribution.
#' @param fixSigma If `TRUE`, the current value of the covariance matrix is taken as known and will not be updated.
#' @param fixCrossBlockCov If `TRUE`, the covariance for outcomes in separate blocks will be taken as known and will not be updated.
#' 
#' @return A new moprobit state container with the current parameters after the requested number of iterations
#' 
#' @seealso [moprobit_init()], [moprobit_chain()]
moprobit_iter <- function(state, iters = 1, TMN_iters = 5, fixSigma = FALSE, fixCrossBlockCov = FALSE) {
  internal_iter(state, iters, TMN_iters, fixSigma, fixCrossBlockCov, eps = sqrt(.Machine$double.eps))
}


#' Multivariate ordinal probit MCMC initialization
#' 
#' Initialize a new MCMC chain for a multivariate ordinal probit model
#' 
#' @param formulas A formula or a named list of formulas specifying blocks of outcomes with common specification. See details.
#' @param dataset The data to be used in estimating the model.
#' @param sd_tau The standard deviation of the proposal distribution for `tau` parameters.
#' @param meas_err A named list of measurement error variances for continuous variables measured with error. Each element should have the same name as a variable in `formulas` and should either be a scalar or a vector of the same length as `dataset`.
#' @param contrasts A named list of factor contrasts. See the `contrasts.arg` of [model.matrix.default()].
#' @param subset Either a logical vector of cases in `dataset` to use for estimation of the entire model, or a named list of logical vectors indicating which cases should be used to estimate each block defined by `formulas`. Note that you must call [moprobit_iter()] with `fixCrossBlockCov = TRUE` if you subset by block.
#' @param initZero If `TRUE`, initialize `beta` with 0 and `tau` with whole numbers. Otherwise, initial values will be obtained from univariate models.
#' 
#' @return A moprobit state container for use by [moprobit_iter()]
#' 
#' @details Formulas may contain main effects and interaction terms specified using `*` or `:`, as with [lm()].
#' Do not include higher-order terms or computed terms using [I()].
#' Outcome variables, on the left side of the formula's `~` should be concatenated with `+` (note that this usage
#' differs from the `cbind` convention of [lm()]). A variable may be included as an outcome variable (on the left side)
#' in only one block. A variable may be included as an outcome variable and a predictor variable (on the right side), but
#' variables should generally be included as predictors only in blocks that come *after* the block in which the variable
#' is an outcome. Outcome variables may have missing data, but predictors that are not also outcomes may not have any
#' missing data in `dataset`. One strategy for handling missing data in predictors is to include a "base block" that lists
#' as outcomes any variables with missing data that would otherwise only serve as predictors. This base block may either
#' include only an intercept on the right (`~ 1`) or may include the set of predictors for which there is no missing data.
#' 
#' @seealso [moprobit_iter()], [chain_to_mcmc()]
moprobit_init <- function(formulas, dataset, sd_tau, meas_err = NULL, contrasts = NULL, subset = NULL, initZero = FALSE) {
  
  env <- new.env()
  state <- list(env=env)
  
  if (!is.list(formulas)) formulas <- list(formulas)
  env$G <- length(formulas)
  env$formulas <- formulas
  env$contrasts <- contrasts
  env$sd_tau <- sd_tau
  # FIXME: check sd_tau, allow missing if no ordinal variables
  
  if (!is.null(subset)) {
    # If only one block and we subset, just subset the dataset
    if (length(formulas) == 1) {
      if (is.list(subset)) {
        if (length(subset) != 1)
          stop("Only one block, but length(subset) > 1")
        subset <- subset[[1]]
      }
      if (!is.logical(subset))
        stop("subset must be a logical vector")
      dataset <- dataset[subset,]
    } else {
      if (!all(sapply(subset, is.logical)))
        stop("subset must be logical vectors")
      # Set subset by names
      # FIXME: Add option to subset for every block by position
      if (!all(names(subset) %in% names(formulas)))
        stop("Unknown subset block names: ", setdiff(names(subset), names(formulas)))
      env$subset <- lapply(seq_along(formulas), function(i) 1:nrow(dataset))
      for (g in names(subset)) env$subset[[g]] <- which(subset[[g]])
    }
  }

  # Accumulate predictors and outcomes across formulas
  removeEmpty <- function(x) x[x != '']
  outcomes <- lapply(formulas, function(f) removeEmpty(strsplit(paste(deparse(f[[2]]), collapse='+'), '\\s*\\+\\s*')[[1]]))
  predictors <- lapply(formulas, function(f) paste(deparse(f[[3]]), collapse=' + ') )
  if (length(unique(do.call(c, outcomes))) < sum(sapply(outcomes, length)))
    stop('Duplicate outcome')
  
  # Outcomes frame
  env$Y <- model.frame(formula(paste0('~ ', paste(do.call(c, outcomes), collapse='+'))), dataset, na.action = na.pass)
  q.names <- colnames(env$Y);   q <- length(q.names)
  n.names <- rownames(env$Y);   n <- length(n.names)
  env$q.block <- matrix(sapply(outcomes, function(o) q.names %in% o), q, env$G)
  colnames(env$q.block) <- names(outcomes)
  row.names(env$q.block) <- q.names
  
  # Outcome types
  for (j in which(sapply(env$Y, is.character))) env$Y[,j] <- factor(env$Y[,j])
  env$Y.logical <- sapply(env$Y, is.logical)
  env$Y.factor <- sapply(env$Y, is.factor)
  env$Y.continuous <- !(env$Y.logical | env$Y.factor)
  env$Y.fixed <- !env$Y.continuous

  # Predictors frame
  env$f <- formula(paste0('~ ', paste(predictors, collapse='+')))
  predictors.frame <- model.frame(env$f, dataset, na.action = na.pass)
  if (!is.null(contrasts) && !all(names(contrasts) %in% colnames(predictors.frame))) {
    warning("Contrasts ignored for absent variable: ", setdiff(names(contrasts), colnames(predictors.frame)))
    env$contrasts <- env$contrasts[names(env$contrasts %in% colnames(predictors.frame))]
  }
  env$X <- predictors.frame[, !(colnames(predictors.frame) %in% colnames(env$Y)), drop=F]  # Base predictors (not also outcomes)
  if (any(is.na(env$X)))
    stop("Missing data in base predictors")
  p.names <- colnames(model.matrix(env$f, dataset, env$contrasts, na.action = na.pass))
  p <- length(p.names)
  env$p.block <- matrix(sapply(predictors, function(p) {
    pfx <- formula(paste0('~', p))
    pfm <- model.frame(pfx, dataset, na.action = na.pass)
    pc <- if (is.null(env$contrasts)) NULL else env$contrasts[names(env$contrasts) %in% colnames(pfm)]
    p.names %in% colnames(model.matrix(pfx, pfm, pc, na.action = na.pass))
  }), p, env$G)
  colnames(env$p.block) <- names(predictors)
  row.names(env$p.block) <- p.names
  
  env$Y.mis <- lapply(env$Y, function(y) which(is.na(y)) )
  env$Y.obs <- lapply(env$Y, function(y) which(!is.na(y)) )
  env$N.mis <- sapply(env$Y.mis, length)
  env$N.obs <- n - env$N.mis
  env$K <- as.integer(sapply(env$Y, function(x) if (is.logical(x)) 2 else if (is.factor(x)) nlevels(x) else 0))
  
  # Reciprocal of the measurement error variance
  if (is.null(meas_err)) {
    env$meas_err <- rep(list(NULL), q)
  } else {
    if (length(setdiff(names(meas_err), names(env$Y))) > 0)
      warning("Measurement error variances supplied for unknown outcomes will be ignored: ", setdiff(names(meas_err), names(env$Y)) )
    if (any(names(meas_err) %in% names(env$Y)[!env$Y.continuous]))
      warning("Measurement error variances supplied for non-coninuous outcomes will be ignored: ",
              names(meas_err)[which(names(meas_err) %in% names(env$Y)[!env$Y.continuous])])
    env$meas_err <- lapply(names(env$Y), function(j)
      if (j %in% names(meas_err)) {
        x <- meas_err[[j]]
        if (length(x) > 1) ifelse(is.na(x) | x == 0, 0, 1/x) else
                             rep(if (x == 0) 0 else 1/x, n)
      } else NULL)
    names(env$meas_err) <- q.names
    env$Y.mev <- lapply(names(env$Y), function(j)
      if (!is.null(env$meas_err[[j]]))
        ifelse(is.na(env$Y[[j]]), 0, env$Y[[j]] * env$meas_err[[j]])
      else
        NULL)
    names(env$Y.mev) <- q.names
  }

  # Fill in missing data with an initial value
  # FIXME: Would be better to use XB, building up from group 1 to G
  state$Y <- env$Y
  for (j in seq_along(state$Y))
    if (env$N.mis[j] > 0)
      state$Y[env$Y.mis[[j]],j] <- if (env$K[j] == 0 | is.logical(env$Y[[j]])) FALSE else first(levels(env$Y[[j]]))
  
  state$X <- model.matrix(env$f, cbind(state$Y, env$X), env$contrasts)
  rownames(state$X) <- n.names
  
  state$Sigma <- diag(q)
  rownames(state$Sigma) <- colnames(state$Sigma) <- q.names
  state$Omega <- state$L_Sigma <- state$D_inv_Sigma <- state$Sigma
  
  if (initZero) {
    state$beta <- Matrix(0, p, q)
    state$tau <- lapply(1:q, function(j) if (env$K[j] == 0) NULL else 0:(env$K[j]-2))
  } else {
  # Initial estimates for beta, tau
    state$beta <- Matrix(0, p, q)
    state$tau <- lapply(1:q, function(j) NULL)
    for (g in 1:env$G) {
      # Predictors for this block
      p.j <- env$p.block[,g]
      Xtilde <- state$X[,p.j]
      if (sum(p.j) > 1)
        Xtilde0 <- if (colnames(Xtilde)[1] == '(Intercept)') Xtilde[,-1] else Xtilde
      # Each outcome in this block
      for (j in which(env$q.block[,g])) {
        if (env$Y.continuous[j]) {
          # This is a continuous outcome
          m <- lm(state$Y[,j] ~ 0 + Xtilde)
          state$beta[p.j, j] <- coef(m)
          state$Sigma[j,j] <- var(residuals(m))
          state$Omega[j,j] <- 1/state$Sigma[j,j]
          state$L_Sigma[j,j] <- sqrt(state$Sigma[j,j])
          state$D_inv_Sigma[j,j] <- 1/state$L_Sigma[j,j]
        } else if (env$K[j] == 2) {
          # This is a binary outcome
          state$beta[p.j, j] <- coef(glm(state$Y[,j] ~ 0 + Xtilde, binomial(link='probit')))
          state$tau[[j]] <- 0
        } else {
          # This is an ordinal outcome
          if (sum(p.j) > 1)
            m <- MASS::polr(factor(state$Y[,j]) ~ Xtilde0, method = 'probit')
          else
            m <- MASS::polr(factor(state$Y[,j]) ~ 1, method = 'probit')
          if (any(is.na(m$zeta)) || (length(m$coefficients) != (sum(p.j)-1)))
            stop("Error initializing coefficients for ", colnames(state$Z)[j], " from ordinal probit model. ",
                 "Check for linear dependence in predictors or try initZero = TRUE.")
          state$beta[p.j, j] <- c(m$zeta[1], m$coefficients)
          state$tau[[j]] <- c(0, m$zeta[-1] - m$zeta[1])
        }
        if (any(is.na(state$beta[p.j, j])))
          stop("Error initializing coefficients for block ", names(formulas)[g], " from independent models. ",
               "Check for linear dependence in predictors or try initZero = TRUE.")
      }
    }
  }
  rownames(state$beta) <- p.names
  colnames(state$beta) <- q.names
  names(state$tau) <- q.names
  
  # Latent variable initial values
  state$Z <- as.matrix(sapply(seq_along(state$Y), function(j)
    if (env$K[j] == 0) {
      state$Y[,j]
    } else if (env$Y.logical[j]) {
      c(-.5, .5)[state$Y[,j]+1]
    } else
      mid.pt(state$tau[[j]])[as.integer(state$Y[,j])]
    ))
  state$Z[is.na(state$Z)] <- 0
  colnames(state$Z) <- q.names
  rownames(state$Z) <- n.names
  
  # Derived quantities
  state$mu <- as.matrix(state$X %*% state$beta)
  state$E <- as.matrix(state$Z - state$mu)
  
  ## Set up for efficient updating X = F(Z)
  f.terms <- terms(env$f)
  f.term.names <- attr(f.terms, 'term.labels')
  f.xTerm <- attr(f.terms, 'factors')           # Matrix of variables x term associations in env$f
  f.assign <- attr(state$X, 'assign')           # Vector indicating which term each column of X comes from
  
  # For each outcome variable, a formula consisting of the terms of F(Z) based on it
  env$update.formulas <- lapply(q.names, function(j)
    if (j %in% rownames(f.xTerm))  # if outcome j is also a predictor in F(Z)
      # Get the terms that involve j, and concatenate them into an update formula
      formula(paste0('~ 0 + ', paste(f.term.names[f.xTerm[j,] != 0], collapse=' + ')))
    else NULL)
  
  # For each outcome variable, the contrasts used in its update formula
  env$update.contrasts <- lapply(env$update.formulas, function(f)
    if (is.null(f) || is.null(env$contrasts)) NULL else
      env$contrasts[names(env$contrasts) %in% rownames(attr(terms(f), 'factors'))]
      )
  
  # For each outcome variable, a vector of the columns in X that need to be updated when it changes
  env$update.to <- lapply(q.names, function(j)
    if (j %in% rownames(f.xTerm))  # if outcome j is also a predictor in F(Z)
      # Get the terms that invovle j, and identify which columns of X are based on those terms
      which(f.assign %in% which(f.xTerm[j,] != 0))
    else NULL)
  
  # For each outcome variable, a vector of the columns of the update formula's model matrix aligned to update.to
  env$update.from <- lapply(seq_along(env$update.formulas), function(j)
    if (is.null(env$update.formulas[[j]]))
      NULL
    else  # if outcome j is also a predictor in F(Z)
      # Get the p.names that need to be updated, then find the corresponding column numbers in the update model matrix
      match(sapply(strsplit(p.names[ env$update.to[[j]] ], ':'), function(x) paste(sort(x), collapse=':')),
            sapply(strsplit(colnames(model.matrix(env$update.formulas[[j]], dataset, env$update.contrasts[[j]],
                                                  na.action = na.pass)), ':'),
                   function(x) paste(sort(x), collapse=':')) ) )
  
  # For each outcome variable, a vector of the other outcome variables that are affected via F(Z) when it is updated
  env$update.cascade <- lapply(seq_along(q.names), function(j)
    if (is.null(env$update.formulas[[j]])) NULL else
      # Find the blocks entailed by the columns of X affected when j is updated,
      # then get the outcome variables that belong to those blocks
      which(apply(env$q.block[, apply(env$p.block[env$update.to[[j]],,drop=F], 2, any), drop=F], 1, any)) )
  
  names(env$update.cascade) <- names(env$update.from) <- names(env$update.to) <-
    names(env$update.contrasts) <- names(env$update.formulas) <- q.names
  

  return(state)
}

#' Remove the derived quantities from state
#' 
#' @param state A moprobit state container.
#' 
#' @return The state container with derived quantities removed.
#' 
#' @seealso [derive_state()]
clean_state <- function(state) {
  state$X <- state$Y <- state$mu <- state$E <- NULL
  return(state)
}

#' Recalculate the derived quantities for state
#' 
#' @param state A moprobit state container.
#' 
#' @return The state container with the derived quantities (`Y`, `X`, `mu`, and `E`) recomputed.
#' 
#' @seealso [clean_state()]
derive_state <- function(state) {
  env <- state$env
  # Recover Z -> Y
  state$Y <- data.frame(lapply(1:ncol(state$Z), function(j)
    if (env$K[j] == 0) {
      state$Z[,j]
    } else if (env$Y.logical[j]) {
      state$Z[,j] > 0
    } else {
      factor(sapply(state$Z[,j], function(z) levels(env$Y[,j])[sum(z > state$tau[[j]])+1]), levels=levels(env$Y[,j]))
    }))
  colnames(state$Y) <- colnames(state$Z)
  rownames(state$Y) <- rownames(state$Z)
  # Recover Y -> X
  state$X <- model.matrix(env$f, cbind(state$Y, env$X), env$contrasts)
  # Recover XB -> mu
  state$mu <- state$X %*% state$beta
  # Recover Z-XB -> E
  state$E <- state$Z - state$mu
  return(state)
}
